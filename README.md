# Python-workshop-TSA

In this lecture we are going to learn what is Hadoop and how to perform parallel computing using hadoop.

After this lecture you should be able to:

* understand the structure of HDFS, how files are stored in HDFS and how to exchange files with HDFS;
* understand how MapReduce works and run your own MapReduce program written in python using Hadoop streaming utility;
* write you own PIG script to solve data processing problems in your class project and future research.

# Here are something you need to prepare before the workshop:

## Required:

We will be using INTRANS test cluster in this lecture, but you need to install some software on your laptop to support the connection to the cluster.

## Windows:

1. Putty: 

Download link: https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html

Download the 32-bit or 64-bit based on your system architecture

![Alt text](/figures_support/Putty-download.PNG)


